{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9853438556933484,
                "recall": 0.9721913236929922,
                "f1-score": 0.9787234042553192,
                "support": 899.0
            },
            "1": {
                "precision": 0.9722222222222222,
                "recall": 0.9853603603603603,
                "f1-score": 0.9787472035794182,
                "support": 888.0
            },
            "accuracy": 0.978735310576385,
            "macro avg": {
                "precision": 0.9787830389577853,
                "recall": 0.9787758420266763,
                "f1-score": 0.9787353039173687,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9788234245112778,
                "recall": 0.978735310576385,
                "f1-score": 0.9787352306681899,
                "support": 1787.0
            },
            "cross-entropy": 0.10060165166096087,
            "roc-auc": 0.9968533605908468,
            "score": 0.978735310576385
        },
        "val": {
            "0": {
                "precision": 0.8695652173913043,
                "recall": 0.8264462809917356,
                "f1-score": 0.8474576271186441,
                "support": 121.0
            },
            "1": {
                "precision": 0.8173913043478261,
                "recall": 0.8623853211009175,
                "f1-score": 0.8392857142857143,
                "support": 109.0
            },
            "accuracy": 0.8434782608695652,
            "macro avg": {
                "precision": 0.8434782608695652,
                "recall": 0.8444158010463265,
                "f1-score": 0.8433716707021792,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8448393194706995,
                "recall": 0.8434782608695652,
                "f1-score": 0.8435848510369512,
                "support": 230.0
            },
            "cross-entropy": 0.5627472664549341,
            "roc-auc": 0.8855106528167412,
            "score": 0.8434782608695652
        },
        "test": {
            "0": {
                "precision": 0.8277310924369747,
                "recall": 0.7665369649805448,
                "f1-score": 0.7959595959595959,
                "support": 257.0
            },
            "1": {
                "precision": 0.7993311036789298,
                "recall": 0.8535714285714285,
                "f1-score": 0.8255613126079446,
                "support": 280.0
            },
            "accuracy": 0.8119180633147114,
            "macro avg": {
                "precision": 0.8135310980579522,
                "recall": 0.8100541967759867,
                "f1-score": 0.8107604542837703,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8129229046301729,
                "recall": 0.8119180633147114,
                "f1-score": 0.8113943830388093,
                "support": 537.0
            },
            "cross-entropy": 0.5262871038340071,
            "roc-auc": 0.8741939966648138,
            "score": 0.8119180633147114
        }
    }
}
{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9660377358490566,
                "recall": 0.8571428571428571,
                "f1-score": 0.9083382613837966,
                "support": 896.0
            },
            "1": {
                "precision": 0.8709677419354839,
                "recall": 0.9696969696969697,
                "f1-score": 0.917684545937334,
                "support": 891.0
            },
            "accuracy": 0.9132624510352546,
            "macro avg": {
                "precision": 0.9185027388922702,
                "recall": 0.9134199134199135,
                "f1-score": 0.9130114036605652,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9186357411221437,
                "recall": 0.9132624510352546,
                "f1-score": 0.9129983282764669,
                "support": 1787.0
            },
            "cross-entropy": 0.2627430647634536,
            "roc-auc": 0.9775395322270323,
            "score": 0.9132624510352546
        },
        "val": {
            "0": {
                "precision": 0.8348623853211009,
                "recall": 0.8348623853211009,
                "f1-score": 0.8348623853211009,
                "support": 109.0
            },
            "1": {
                "precision": 0.8512396694214877,
                "recall": 0.8512396694214877,
                "f1-score": 0.8512396694214878,
                "support": 121.0
            },
            "accuracy": 0.8434782608695652,
            "macro avg": {
                "precision": 0.8430510273712943,
                "recall": 0.8430510273712943,
                "f1-score": 0.8430510273712943,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8434782608695652,
                "recall": 0.8434782608695652,
                "f1-score": 0.8434782608695652,
                "support": 230.0
            },
            "cross-entropy": 0.3668579337119645,
            "roc-auc": 0.9215255136856473,
            "score": 0.8434782608695652
        },
        "test": {
            "0": {
                "precision": 0.8454935622317596,
                "recall": 0.7242647058823529,
                "f1-score": 0.7801980198019802,
                "support": 272.0
            },
            "1": {
                "precision": 0.7532894736842105,
                "recall": 0.8641509433962264,
                "f1-score": 0.8049209138840069,
                "support": 265.0
            },
            "accuracy": 0.7932960893854749,
            "macro avg": {
                "precision": 0.7993915179579851,
                "recall": 0.7942078246392896,
                "f1-score": 0.7925594668429936,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7999924757045705,
                "recall": 0.7932960893854749,
                "f1-score": 0.7923983306618257,
                "support": 537.0
            },
            "cross-entropy": 0.4556400038110114,
            "roc-auc": 0.8654550499445062,
            "score": 0.7932960893854749
        }
    }
}
{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9582392776523702,
                "recall": 0.9464882943143813,
                "f1-score": 0.9523275378575434,
                "support": 897.0
            },
            "1": {
                "precision": 0.946725860155383,
                "recall": 0.9584269662921349,
                "f1-score": 0.9525404801786712,
                "support": 890.0
            },
            "accuracy": 0.9524342473419138,
            "macro avg": {
                "precision": 0.9524825689038765,
                "recall": 0.9524576303032581,
                "f1-score": 0.9524340090181074,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9525051189661258,
                "recall": 0.9524342473419138,
                "f1-score": 0.952433591951446,
                "support": 1787.0
            },
            "cross-entropy": 0.18462291558353833,
            "roc-auc": 0.9886074680896372,
            "score": 0.9524342473419138
        },
        "val": {
            "0": {
                "precision": 0.7829457364341085,
                "recall": 0.8347107438016529,
                "f1-score": 0.8079999999999999,
                "support": 121.0
            },
            "1": {
                "precision": 0.801980198019802,
                "recall": 0.7431192660550459,
                "f1-score": 0.7714285714285715,
                "support": 109.0
            },
            "accuracy": 0.7913043478260869,
            "macro avg": {
                "precision": 0.7924629672269552,
                "recall": 0.7889150049283493,
                "f1-score": 0.7897142857142857,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.7919664160551544,
                "recall": 0.7913043478260869,
                "f1-score": 0.7906683229813664,
                "support": 230.0
            },
            "cross-entropy": 0.47776692848300806,
            "roc-auc": 0.8682235195996665,
            "score": 0.7913043478260869
        },
        "test": {
            "0": {
                "precision": 0.7803921568627451,
                "recall": 0.7683397683397684,
                "f1-score": 0.77431906614786,
                "support": 259.0
            },
            "1": {
                "precision": 0.7872340425531915,
                "recall": 0.7985611510791367,
                "f1-score": 0.7928571428571429,
                "support": 278.0
            },
            "accuracy": 0.7839851024208566,
            "macro avg": {
                "precision": 0.7838130997079683,
                "recall": 0.7834504597094525,
                "f1-score": 0.7835881045025015,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7839341386540749,
                "recall": 0.7839851024208566,
                "f1-score": 0.783916059304621,
                "support": 537.0
            },
            "cross-entropy": 0.49948054006207404,
            "roc-auc": 0.8511013582956029,
            "score": 0.7839851024208566
        }
    }
}
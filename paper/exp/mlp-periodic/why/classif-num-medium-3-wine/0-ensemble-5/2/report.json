{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9771908763505402,
                "recall": 0.9034406215316315,
                "f1-score": 0.9388696655132641,
                "support": 901.0
            },
            "1": {
                "precision": 0.9088050314465409,
                "recall": 0.9785553047404063,
                "f1-score": 0.942391304347826,
                "support": 886.0
            },
            "accuracy": 0.9406827084499161,
            "macro avg": {
                "precision": 0.9429979538985406,
                "recall": 0.9409979631360189,
                "f1-score": 0.9406304849305451,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9432849677971304,
                "recall": 0.9406827084499161,
                "f1-score": 0.9406157046892137,
                "support": 1787.0
            },
            "cross-entropy": 0.18458915024470907,
            "roc-auc": 0.9875934188999933,
            "score": 0.9406827084499161
        },
        "val": {
            "0": {
                "precision": 0.8367346938775511,
                "recall": 0.7256637168141593,
                "f1-score": 0.7772511848341233,
                "support": 113.0
            },
            "1": {
                "precision": 0.7651515151515151,
                "recall": 0.8632478632478633,
                "f1-score": 0.8112449799196787,
                "support": 117.0
            },
            "accuracy": 0.7956521739130434,
            "macro avg": {
                "precision": 0.8009431045145331,
                "recall": 0.7944557900310113,
                "f1-score": 0.7942480823769009,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8003206420908284,
                "recall": 0.7956521739130434,
                "f1-score": 0.7945436805950363,
                "support": 230.0
            },
            "cross-entropy": 0.50595296172127,
            "roc-auc": 0.8548521291884124,
            "score": 0.7956521739130434
        },
        "test": {
            "0": {
                "precision": 0.8071748878923767,
                "recall": 0.6844106463878327,
                "f1-score": 0.7407407407407407,
                "support": 263.0
            },
            "1": {
                "precision": 0.7356687898089171,
                "recall": 0.843065693430657,
                "f1-score": 0.7857142857142857,
                "support": 274.0
            },
            "accuracy": 0.7653631284916201,
            "macro avg": {
                "precision": 0.7714218388506469,
                "recall": 0.7637381699092448,
                "f1-score": 0.7632275132275133,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7706894672687864,
                "recall": 0.7653631284916201,
                "f1-score": 0.7636881361276148,
                "support": 537.0
            },
            "cross-entropy": 0.5077856453812221,
            "roc-auc": 0.860397990619189,
            "score": 0.7653631284916201
        }
    }
}
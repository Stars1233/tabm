{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9944008958566629,
                "recall": 0.9910714285714286,
                "f1-score": 0.9927333705980994,
                "support": 896.0
            },
            "1": {
                "precision": 0.9910514541387024,
                "recall": 0.9943883277216611,
                "f1-score": 0.9927170868347339,
                "support": 891.0
            },
            "accuracy": 0.9927252378287633,
            "macro avg": {
                "precision": 0.9927261749976827,
                "recall": 0.9927298781465448,
                "f1-score": 0.9927252287164167,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9927308608422797,
                "recall": 0.9927252378287633,
                "f1-score": 0.9927252514972832,
                "support": 1787.0
            },
            "cross-entropy": 0.07892049678229476,
            "roc-auc": 0.9998872655122655,
            "score": 0.9927252378287633
        },
        "val": {
            "0": {
                "precision": 0.8347826086956521,
                "recall": 0.8807339449541285,
                "f1-score": 0.857142857142857,
                "support": 109.0
            },
            "1": {
                "precision": 0.8869565217391304,
                "recall": 0.8429752066115702,
                "f1-score": 0.8644067796610169,
                "support": 121.0
            },
            "accuracy": 0.8608695652173913,
            "macro avg": {
                "precision": 0.8608695652173912,
                "recall": 0.8618545757828493,
                "f1-score": 0.8607748184019369,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8622306238185254,
                "recall": 0.8608695652173913,
                "f1-score": 0.8609643120328455,
                "support": 230.0
            },
            "cross-entropy": 0.40301981872916054,
            "roc-auc": 0.9245583440746077,
            "score": 0.8608695652173913
        },
        "test": {
            "0": {
                "precision": 0.8393574297188755,
                "recall": 0.7683823529411765,
                "f1-score": 0.8023032629558542,
                "support": 272.0
            },
            "1": {
                "precision": 0.78125,
                "recall": 0.8490566037735849,
                "f1-score": 0.8137432188065099,
                "support": 265.0
            },
            "accuracy": 0.8081936685288641,
            "macro avg": {
                "precision": 0.8103037148594378,
                "recall": 0.8087194783573808,
                "f1-score": 0.808023240881182,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8106824411238998,
                "recall": 0.8081936685288641,
                "f1-score": 0.8079486787853212,
                "support": 537.0
            },
            "cross-entropy": 0.4668600566331987,
            "roc-auc": 0.8914816870144283,
            "score": 0.8081936685288641
        }
    }
}
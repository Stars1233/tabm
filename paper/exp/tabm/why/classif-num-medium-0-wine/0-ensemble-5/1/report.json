{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9943946188340808,
                "recall": 0.9899553571428571,
                "f1-score": 0.9921700223713646,
                "support": 896.0
            },
            "1": {
                "precision": 0.9899441340782122,
                "recall": 0.9943883277216611,
                "f1-score": 0.9921612541993282,
                "support": 891.0
            },
            "accuracy": 0.9921656407386682,
            "macro avg": {
                "precision": 0.9921693764561466,
                "recall": 0.9921718424322591,
                "f1-score": 0.9921656382853464,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9921756026519437,
                "recall": 0.9921656407386682,
                "f1-score": 0.9921656505519553,
                "support": 1787.0
            },
            "cross-entropy": 0.08436406021756368,
            "roc-auc": 0.999834656084656,
            "score": 0.9921656407386682
        },
        "val": {
            "0": {
                "precision": 0.8482142857142857,
                "recall": 0.8715596330275229,
                "f1-score": 0.8597285067873303,
                "support": 109.0
            },
            "1": {
                "precision": 0.8813559322033898,
                "recall": 0.859504132231405,
                "f1-score": 0.8702928870292886,
                "support": 121.0
            },
            "accuracy": 0.8652173913043478,
            "macro avg": {
                "precision": 0.8647851089588378,
                "recall": 0.865531882629464,
                "f1-score": 0.8650106969083095,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8656496736498579,
                "recall": 0.8652173913043478,
                "f1-score": 0.8652862894363604,
                "support": 230.0
            },
            "cross-entropy": 0.40533555285282047,
            "roc-auc": 0.9218287967245432,
            "score": 0.8652173913043478
        },
        "test": {
            "0": {
                "precision": 0.8489795918367347,
                "recall": 0.7647058823529411,
                "f1-score": 0.8046421663442939,
                "support": 272.0
            },
            "1": {
                "precision": 0.7808219178082192,
                "recall": 0.8603773584905661,
                "f1-score": 0.8186714542190306,
                "support": 265.0
            },
            "accuracy": 0.8119180633147114,
            "macro avg": {
                "precision": 0.8149007548224769,
                "recall": 0.8125416204217536,
                "f1-score": 0.8116568102816623,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8153449854725696,
                "recall": 0.8119180633147114,
                "f1-score": 0.811565371720095,
                "support": 537.0
            },
            "cross-entropy": 0.4572743750832838,
            "roc-auc": 0.8921198668146505,
            "score": 0.8119180633147114
        }
    }
}
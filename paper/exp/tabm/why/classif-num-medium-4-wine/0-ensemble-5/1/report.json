{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.967706013363029,
                "recall": 0.9666295884315906,
                "f1-score": 0.9671675013912076,
                "support": 899.0
            },
            "1": {
                "precision": 0.9662542182227222,
                "recall": 0.9673423423423423,
                "f1-score": 0.9667979741136747,
                "support": 888.0
            },
            "accuracy": 0.9669837716843872,
            "macro avg": {
                "precision": 0.9669801157928756,
                "recall": 0.9669859653869665,
                "f1-score": 0.9669827377524411,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9669845841047232,
                "recall": 0.9669837716843872,
                "f1-score": 0.9669838750775819,
                "support": 1787.0
            },
            "cross-entropy": 0.1564030786461103,
            "roc-auc": 0.99596523664933,
            "score": 0.9669837716843872
        },
        "val": {
            "0": {
                "precision": 0.8672566371681416,
                "recall": 0.8099173553719008,
                "f1-score": 0.8376068376068375,
                "support": 121.0
            },
            "1": {
                "precision": 0.8034188034188035,
                "recall": 0.8623853211009175,
                "f1-score": 0.8318584070796462,
                "support": 109.0
            },
            "accuracy": 0.8347826086956521,
            "macro avg": {
                "precision": 0.8353377202934725,
                "recall": 0.8361513382364092,
                "f1-score": 0.8347326223432419,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8370030550869335,
                "recall": 0.8347826086956521,
                "f1-score": 0.8348825814004729,
                "support": 230.0
            },
            "cross-entropy": 0.45757839320793,
            "roc-auc": 0.8792175297596482,
            "score": 0.8347826086956521
        },
        "test": {
            "0": {
                "precision": 0.7911646586345381,
                "recall": 0.7665369649805448,
                "f1-score": 0.7786561264822135,
                "support": 257.0
            },
            "1": {
                "precision": 0.7916666666666666,
                "recall": 0.8142857142857143,
                "f1-score": 0.8028169014084506,
                "support": 280.0
            },
            "accuracy": 0.7914338919925512,
            "macro avg": {
                "precision": 0.7914156626506024,
                "recall": 0.7904113396331296,
                "f1-score": 0.7907365139453321,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.791426413288162,
                "recall": 0.7914338919925512,
                "f1-score": 0.7912539234642366,
                "support": 537.0
            },
            "cross-entropy": 0.45604487844763614,
            "roc-auc": 0.8664396887159533,
            "score": 0.7914338919925512
        }
    }
}
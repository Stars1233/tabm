{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9835294117647059,
                "recall": 0.9319955406911928,
                "f1-score": 0.9570692615912993,
                "support": 897.0
            },
            "1": {
                "precision": 0.9348986125933831,
                "recall": 0.9842696629213483,
                "f1-score": 0.9589490968801314,
                "support": 890.0
            },
            "accuracy": 0.9580302182428652,
            "macro avg": {
                "precision": 0.9592140121790445,
                "recall": 0.9581326018062706,
                "f1-score": 0.9580091792357154,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.959309259967013,
                "recall": 0.9580302182428652,
                "f1-score": 0.9580054974094642,
                "support": 1787.0
            },
            "cross-entropy": 0.16407568421315927,
            "roc-auc": 0.9954392293913544,
            "score": 0.9580302182428652
        },
        "val": {
            "0": {
                "precision": 0.808695652173913,
                "recall": 0.768595041322314,
                "f1-score": 0.7881355932203389,
                "support": 121.0
            },
            "1": {
                "precision": 0.7565217391304347,
                "recall": 0.7981651376146789,
                "f1-score": 0.7767857142857142,
                "support": 109.0
            },
            "accuracy": 0.782608695652174,
            "macro avg": {
                "precision": 0.7826086956521738,
                "recall": 0.7833800894684965,
                "f1-score": 0.7824606537530265,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.7839697542533081,
                "recall": 0.782608695652174,
                "f1-score": 0.782756737551321,
                "support": 230.0
            },
            "cross-entropy": 0.49325847685670127,
            "roc-auc": 0.8551823489271363,
            "score": 0.782608695652174
        },
        "test": {
            "0": {
                "precision": 0.8097345132743363,
                "recall": 0.7065637065637066,
                "f1-score": 0.7546391752577319,
                "support": 259.0
            },
            "1": {
                "precision": 0.7556270096463023,
                "recall": 0.8453237410071942,
                "f1-score": 0.797962648556876,
                "support": 278.0
            },
            "accuracy": 0.7783985102420856,
            "macro avg": {
                "precision": 0.7826807614603193,
                "recall": 0.7759437237854504,
                "f1-score": 0.776300911907304,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7817235523644789,
                "recall": 0.7783985102420856,
                "f1-score": 0.7770673420680896,
                "support": 537.0
            },
            "cross-entropy": 0.49378663993762284,
            "roc-auc": 0.8465875947890337,
            "score": 0.7783985102420856
        }
    }
}
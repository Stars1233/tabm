{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9857482185273159,
                "recall": 0.9253065774804905,
                "f1-score": 0.9545715928694652,
                "support": 897.0
            },
            "1": {
                "precision": 0.9291005291005291,
                "recall": 0.9865168539325843,
                "f1-score": 0.9569482288828338,
                "support": 890.0
            },
            "accuracy": 0.9557918298824846,
            "macro avg": {
                "precision": 0.9574243738139225,
                "recall": 0.9559117157065373,
                "f1-score": 0.9557599108761495,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9575353234014959,
                "recall": 0.9557918298824846,
                "f1-score": 0.9557552560210589,
                "support": 1787.0
            },
            "cross-entropy": 0.18989408921026688,
            "roc-auc": 0.9934726241028147,
            "score": 0.9557918298824846
        },
        "val": {
            "0": {
                "precision": 0.8050847457627118,
                "recall": 0.7851239669421488,
                "f1-score": 0.794979079497908,
                "support": 121.0
            },
            "1": {
                "precision": 0.7678571428571429,
                "recall": 0.7889908256880734,
                "f1-score": 0.7782805429864253,
                "support": 109.0
            },
            "accuracy": 0.7869565217391304,
            "macro avg": {
                "precision": 0.7864709443099274,
                "recall": 0.7870573963151111,
                "f1-score": 0.7866298112421667,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.7874420991683334,
                "recall": 0.7869565217391304,
                "f1-score": 0.7870654252381183,
                "support": 230.0
            },
            "cross-entropy": 0.4787927910238578,
            "roc-auc": 0.8575327924785806,
            "score": 0.7869565217391304
        },
        "test": {
            "0": {
                "precision": 0.820627802690583,
                "recall": 0.7065637065637066,
                "f1-score": 0.7593360995850622,
                "support": 259.0
            },
            "1": {
                "precision": 0.7579617834394905,
                "recall": 0.8561151079136691,
                "f1-score": 0.8040540540540541,
                "support": 278.0
            },
            "accuracy": 0.7839851024208566,
            "macro avg": {
                "precision": 0.7892947930650367,
                "recall": 0.7813394072386879,
                "f1-score": 0.7816950768195581,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.788186176337131,
                "recall": 0.7839851024208566,
                "f1-score": 0.782486176572734,
                "support": 537.0
            },
            "cross-entropy": 0.48145909369580975,
            "roc-auc": 0.846115385683731,
            "score": 0.7839851024208566
        }
    }
}
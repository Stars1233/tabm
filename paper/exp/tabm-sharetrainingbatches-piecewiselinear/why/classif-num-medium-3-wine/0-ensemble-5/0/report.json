{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 0.9966703662597114,
                "f1-score": 0.9983324068927182,
                "support": 901.0
            },
            "1": {
                "precision": 0.9966254218222722,
                "recall": 1.0,
                "f1-score": 0.9983098591549296,
                "support": 886.0
            },
            "accuracy": 0.9983212087297146,
            "macro avg": {
                "precision": 0.998312710911136,
                "recall": 0.9983351831298557,
                "f1-score": 0.998321133023824,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9983268739421003,
                "recall": 0.9983212087297146,
                "f1-score": 0.9983212276561874,
                "support": 1787.0
            },
            "cross-entropy": 0.049251331279702666,
            "roc-auc": 0.9999899785289984,
            "score": 0.9983212087297146
        },
        "val": {
            "0": {
                "precision": 0.8425925925925926,
                "recall": 0.8053097345132744,
                "f1-score": 0.8235294117647058,
                "support": 113.0
            },
            "1": {
                "precision": 0.819672131147541,
                "recall": 0.8547008547008547,
                "f1-score": 0.8368200836820083,
                "support": 117.0
            },
            "accuracy": 0.8304347826086956,
            "macro avg": {
                "precision": 0.8311323618700668,
                "recall": 0.8300052946070645,
                "f1-score": 0.8301747477233571,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8309330535096751,
                "recall": 0.8304347826086956,
                "f1-score": 0.8302903187835075,
                "support": 230.0
            },
            "cross-entropy": 0.47602059270948055,
            "roc-auc": 0.8796611451478709,
            "score": 0.8304347826086956
        },
        "test": {
            "0": {
                "precision": 0.8270042194092827,
                "recall": 0.7452471482889734,
                "f1-score": 0.7839999999999999,
                "support": 263.0
            },
            "1": {
                "precision": 0.7766666666666666,
                "recall": 0.8503649635036497,
                "f1-score": 0.8118466898954704,
                "support": 274.0
            },
            "accuracy": 0.7988826815642458,
            "macro avg": {
                "precision": 0.8018354430379746,
                "recall": 0.7978060558963116,
                "f1-score": 0.7979233449477352,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8013198815108157,
                "recall": 0.7988826815642458,
                "f1-score": 0.7982085531310221,
                "support": 537.0
            },
            "cross-entropy": 0.5279439417538565,
            "roc-auc": 0.8664344592156754,
            "score": 0.7988826815642458
        }
    }
}
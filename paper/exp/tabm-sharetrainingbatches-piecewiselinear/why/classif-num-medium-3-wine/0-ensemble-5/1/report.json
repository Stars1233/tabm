{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9977578475336323,
                "recall": 0.9877913429522752,
                "f1-score": 0.992749581706637,
                "support": 901.0
            },
            "1": {
                "precision": 0.9877094972067039,
                "recall": 0.9977426636568849,
                "f1-score": 0.9927007299270073,
                "support": 886.0
            },
            "accuracy": 0.9927252378287633,
            "macro avg": {
                "precision": 0.9927336723701681,
                "recall": 0.9927670033045801,
                "f1-score": 0.9927251558168222,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9927758450771922,
                "recall": 0.9927252378287633,
                "f1-score": 0.9927253608466752,
                "support": 1787.0
            },
            "cross-entropy": 0.08870655369741334,
            "roc-auc": 0.9998922691867326,
            "score": 0.9927252378287633
        },
        "val": {
            "0": {
                "precision": 0.8446601941747572,
                "recall": 0.7699115044247787,
                "f1-score": 0.8055555555555555,
                "support": 113.0
            },
            "1": {
                "precision": 0.7952755905511811,
                "recall": 0.8632478632478633,
                "f1-score": 0.8278688524590164,
                "support": 117.0
            },
            "accuracy": 0.8173913043478261,
            "macro avg": {
                "precision": 0.8199678923629692,
                "recall": 0.8165796838363211,
                "f1-score": 0.816712204007286,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.819538461027112,
                "recall": 0.8173913043478261,
                "f1-score": 0.8169062326760117,
                "support": 230.0
            },
            "cross-entropy": 0.4421380513648005,
            "roc-auc": 0.8856364874063989,
            "score": 0.8173913043478261
        },
        "test": {
            "0": {
                "precision": 0.8478260869565217,
                "recall": 0.7414448669201521,
                "f1-score": 0.7910750507099391,
                "support": 263.0
            },
            "1": {
                "precision": 0.7785016286644951,
                "recall": 0.8722627737226277,
                "f1-score": 0.8227194492254734,
                "support": 274.0
            },
            "accuracy": 0.8081936685288641,
            "macro avg": {
                "precision": 0.8131638578105085,
                "recall": 0.80685382032139,
                "f1-score": 0.8068972499677063,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8124538307702736,
                "recall": 0.8081936685288641,
                "f1-score": 0.8072213546079957,
                "support": 537.0
            },
            "cross-entropy": 0.4959396248584214,
            "roc-auc": 0.8685298770503178,
            "score": 0.8081936685288641
        }
    }
}
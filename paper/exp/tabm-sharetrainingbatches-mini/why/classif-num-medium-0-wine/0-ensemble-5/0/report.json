{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.996606334841629,
                "recall": 0.9832589285714286,
                "f1-score": 0.9898876404494382,
                "support": 896.0
            },
            "1": {
                "precision": 0.9833887043189369,
                "recall": 0.9966329966329966,
                "f1-score": 0.9899665551839464,
                "support": 891.0
            },
            "accuracy": 0.9899272523782876,
            "macro avg": {
                "precision": 0.9899975195802829,
                "recall": 0.9899459626022127,
                "f1-score": 0.9899270978166923,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.990016010949229,
                "recall": 0.9899272523782876,
                "f1-score": 0.9899269874155529,
                "support": 1787.0
            },
            "cross-entropy": 0.10851414501859288,
            "roc-auc": 0.9995252625460959,
            "score": 0.9899272523782876
        },
        "val": {
            "0": {
                "precision": 0.8421052631578947,
                "recall": 0.8807339449541285,
                "f1-score": 0.8609865470852017,
                "support": 109.0
            },
            "1": {
                "precision": 0.8879310344827587,
                "recall": 0.8512396694214877,
                "f1-score": 0.869198312236287,
                "support": 121.0
            },
            "accuracy": 0.8652173913043478,
            "macro avg": {
                "precision": 0.8650181488203267,
                "recall": 0.8659868071878081,
                "f1-score": 0.8650924296607443,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8662136037244534,
                "recall": 0.8652173913043478,
                "f1-score": 0.8653066496212074,
                "support": 230.0
            },
            "cross-entropy": 0.3449968471712645,
            "roc-auc": 0.9350216089165213,
            "score": 0.8652173913043478
        },
        "test": {
            "0": {
                "precision": 0.832,
                "recall": 0.7647058823529411,
                "f1-score": 0.7969348659003832,
                "support": 272.0
            },
            "1": {
                "precision": 0.7770034843205574,
                "recall": 0.8415094339622642,
                "f1-score": 0.8079710144927537,
                "support": 265.0
            },
            "accuracy": 0.8026070763500931,
            "macro avg": {
                "precision": 0.8045017421602787,
                "recall": 0.8031076581576027,
                "f1-score": 0.8024529401965684,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8048601924486922,
                "recall": 0.8026070763500931,
                "f1-score": 0.8023810099915902,
                "support": 537.0
            },
            "cross-entropy": 0.47168204509465317,
            "roc-auc": 0.8748196448390678,
            "score": 0.8026070763500931
        }
    }
}
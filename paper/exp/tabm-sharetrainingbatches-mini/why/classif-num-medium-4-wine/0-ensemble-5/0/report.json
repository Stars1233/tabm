{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9911012235817576,
                "recall": 0.9911012235817576,
                "f1-score": 0.9911012235817576,
                "support": 899.0
            },
            "1": {
                "precision": 0.990990990990991,
                "recall": 0.990990990990991,
                "f1-score": 0.990990990990991,
                "support": 888.0
            },
            "accuracy": 0.9910464465584778,
            "macro avg": {
                "precision": 0.9910461072863743,
                "recall": 0.9910461072863743,
                "f1-score": 0.9910461072863743,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9910464465584778,
                "recall": 0.9910464465584778,
                "f1-score": 0.9910464465584778,
                "support": 1787.0
            },
            "cross-entropy": 0.08333563095891379,
            "roc-auc": 0.9997832927476976,
            "score": 0.9910464465584778
        },
        "val": {
            "0": {
                "precision": 0.8849557522123894,
                "recall": 0.8264462809917356,
                "f1-score": 0.8547008547008548,
                "support": 121.0
            },
            "1": {
                "precision": 0.8205128205128205,
                "recall": 0.8807339449541285,
                "f1-score": 0.8495575221238938,
                "support": 109.0
            },
            "accuracy": 0.8521739130434782,
            "macro avg": {
                "precision": 0.852734286362605,
                "recall": 0.853590112972932,
                "f1-score": 0.8521291884123743,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8544154063199849,
                "recall": 0.8521739130434782,
                "f1-score": 0.8522633623056863,
                "support": 230.0
            },
            "cross-entropy": 0.49270782225879856,
            "roc-auc": 0.884070058381985,
            "score": 0.8521739130434782
        },
        "test": {
            "0": {
                "precision": 0.7926829268292683,
                "recall": 0.7587548638132295,
                "f1-score": 0.7753479125248508,
                "support": 257.0
            },
            "1": {
                "precision": 0.7869415807560137,
                "recall": 0.8178571428571428,
                "f1-score": 0.8021015761821365,
                "support": 280.0
            },
            "accuracy": 0.7895716945996276,
            "macro avg": {
                "precision": 0.7898122537926411,
                "recall": 0.7883060033351862,
                "f1-score": 0.7887247443534937,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7896893013162118,
                "recall": 0.7895716945996276,
                "f1-score": 0.7892976812847019,
                "support": 537.0
            },
            "cross-entropy": 0.47505095210097276,
            "roc-auc": 0.8707754307948861,
            "score": 0.7895716945996276
        }
    }
}
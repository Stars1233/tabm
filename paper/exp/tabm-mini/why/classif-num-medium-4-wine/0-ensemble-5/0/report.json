{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9898534385569335,
                "recall": 0.9766407119021134,
                "f1-score": 0.9832026875699889,
                "support": 899.0
            },
            "1": {
                "precision": 0.9766666666666667,
                "recall": 0.9898648648648649,
                "f1-score": 0.9832214765100672,
                "support": 888.0
            },
            "accuracy": 0.983212087297146,
            "macro avg": {
                "precision": 0.9832600526118,
                "recall": 0.9832527883834892,
                "f1-score": 0.9832120820400281,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9833006386472765,
                "recall": 0.983212087297146,
                "f1-score": 0.9832120242117289,
                "support": 1787.0
            },
            "cross-entropy": 0.12113890055100006,
            "roc-auc": 0.9990216857569472,
            "score": 0.983212087297146
        },
        "val": {
            "0": {
                "precision": 0.8761061946902655,
                "recall": 0.8181818181818182,
                "f1-score": 0.8461538461538463,
                "support": 121.0
            },
            "1": {
                "precision": 0.811965811965812,
                "recall": 0.8715596330275229,
                "f1-score": 0.8407079646017699,
                "support": 109.0
            },
            "accuracy": 0.8434782608695652,
            "macro avg": {
                "precision": 0.8440360033280387,
                "recall": 0.8448707256046706,
                "f1-score": 0.8434309053778081,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8457092307034593,
                "recall": 0.8434782608695652,
                "f1-score": 0.8435729718530796,
                "support": 230.0
            },
            "cross-entropy": 0.4318984574315661,
            "roc-auc": 0.89059064371825,
            "score": 0.8434782608695652
        },
        "test": {
            "0": {
                "precision": 0.8237885462555066,
                "recall": 0.7276264591439688,
                "f1-score": 0.7727272727272727,
                "support": 257.0
            },
            "1": {
                "precision": 0.7741935483870968,
                "recall": 0.8571428571428571,
                "f1-score": 0.8135593220338982,
                "support": 280.0
            },
            "accuracy": 0.7951582867783985,
            "macro avg": {
                "precision": 0.7989910473213017,
                "recall": 0.792384658143413,
                "f1-score": 0.7931432973805854,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7979289570503767,
                "recall": 0.7951582867783985,
                "f1-score": 0.7940177267419005,
                "support": 537.0
            },
            "cross-entropy": 0.4325298695764482,
            "roc-auc": 0.8766397998888271,
            "score": 0.7951582867783985
        }
    }
}
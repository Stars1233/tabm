{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9592088998763906,
                "recall": 0.8660714285714286,
                "f1-score": 0.9102639296187683,
                "support": 896.0
            },
            "1": {
                "precision": 0.8773006134969326,
                "recall": 0.9629629629629629,
                "f1-score": 0.9181380417335473,
                "support": 891.0
            },
            "accuracy": 0.9143816452154448,
            "macro avg": {
                "precision": 0.9182547566866616,
                "recall": 0.9145171957671958,
                "f1-score": 0.9142009856761578,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9183693457834431,
                "recall": 0.9143816452154448,
                "f1-score": 0.9141899698505916,
                "support": 1787.0
            },
            "cross-entropy": 0.23513630407390262,
            "roc-auc": 0.977851430976431,
            "score": 0.9143816452154448
        },
        "val": {
            "0": {
                "precision": 0.8260869565217391,
                "recall": 0.8715596330275229,
                "f1-score": 0.8482142857142858,
                "support": 109.0
            },
            "1": {
                "precision": 0.8782608695652174,
                "recall": 0.8347107438016529,
                "f1-score": 0.8559322033898306,
                "support": 121.0
            },
            "accuracy": 0.8521739130434782,
            "macro avg": {
                "precision": 0.8521739130434782,
                "recall": 0.8531351884145879,
                "f1-score": 0.8520732445520582,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8535349716446125,
                "recall": 0.8521739130434782,
                "f1-score": 0.8522745815348984,
                "support": 230.0
            },
            "cross-entropy": 0.34275717596116223,
            "roc-auc": 0.9256198347107439,
            "score": 0.8521739130434782
        },
        "test": {
            "0": {
                "precision": 0.8429752066115702,
                "recall": 0.75,
                "f1-score": 0.7937743190661479,
                "support": 272.0
            },
            "1": {
                "precision": 0.7694915254237288,
                "recall": 0.8566037735849057,
                "f1-score": 0.8107142857142857,
                "support": 265.0
            },
            "accuracy": 0.8026070763500931,
            "macro avg": {
                "precision": 0.8062333660176495,
                "recall": 0.8033018867924528,
                "f1-score": 0.8022443023902168,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8067123099360061,
                "recall": 0.8026070763500931,
                "f1-score": 0.8021338929241676,
                "support": 537.0
            },
            "cross-entropy": 0.4750377208629572,
            "roc-auc": 0.8698806881243064,
            "score": 0.8026070763500931
        }
    }
}
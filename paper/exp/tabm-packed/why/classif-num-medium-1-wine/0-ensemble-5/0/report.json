{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9844271412680756,
                "recall": 0.9866220735785953,
                "f1-score": 0.9855233853006681,
                "support": 897.0
            },
            "1": {
                "precision": 0.9864864864864865,
                "recall": 0.9842696629213483,
                "f1-score": 0.9853768278965129,
                "support": 890.0
            },
            "accuracy": 0.9854504756575265,
            "macro avg": {
                "precision": 0.985456813877281,
                "recall": 0.9854458682499718,
                "f1-score": 0.9854501065985906,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9854527804647101,
                "recall": 0.9854504756575265,
                "f1-score": 0.9854503936444297,
                "support": 1787.0
            },
            "cross-entropy": 0.08205029649199921,
            "roc-auc": 0.9991331905352424,
            "score": 0.9854504756575265
        },
        "val": {
            "0": {
                "precision": 0.8031496062992126,
                "recall": 0.8429752066115702,
                "f1-score": 0.8225806451612903,
                "support": 121.0
            },
            "1": {
                "precision": 0.8155339805825242,
                "recall": 0.7706422018348624,
                "f1-score": 0.7924528301886793,
                "support": 109.0
            },
            "accuracy": 0.808695652173913,
            "macro avg": {
                "precision": 0.8093417934408684,
                "recall": 0.8068087042232164,
                "f1-score": 0.8075167376749848,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8090187228073907,
                "recall": 0.808695652173913,
                "f1-score": 0.8083026806742702,
                "support": 230.0
            },
            "cross-entropy": 0.512175534655614,
            "roc-auc": 0.8739858973386914,
            "score": 0.808695652173913
        },
        "test": {
            "0": {
                "precision": 0.8114754098360656,
                "recall": 0.7644787644787645,
                "f1-score": 0.7872763419483102,
                "support": 259.0
            },
            "1": {
                "precision": 0.7918088737201365,
                "recall": 0.8345323741007195,
                "f1-score": 0.8126094570928197,
                "support": 278.0
            },
            "accuracy": 0.8007448789571695,
            "macro avg": {
                "precision": 0.801642141778101,
                "recall": 0.7995055692897419,
                "f1-score": 0.799942899520565,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8012942235414133,
                "recall": 0.8007448789571695,
                "f1-score": 0.800391064499844,
                "support": 537.0
            },
            "cross-entropy": 0.5701235728804745,
            "roc-auc": 0.8544901530513042,
            "score": 0.8007448789571695
        }
    }
}
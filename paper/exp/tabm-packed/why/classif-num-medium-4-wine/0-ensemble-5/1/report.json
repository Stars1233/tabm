{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9944506104328524,
                "recall": 0.996662958843159,
                "f1-score": 0.9955555555555555,
                "support": 899.0
            },
            "1": {
                "precision": 0.9966139954853274,
                "recall": 0.9943693693693694,
                "f1-score": 0.9954904171364151,
                "support": 888.0
            },
            "accuracy": 0.9955232232792389,
            "macro avg": {
                "precision": 0.9955323029590899,
                "recall": 0.9955161641062642,
                "f1-score": 0.9955229863459854,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9955256445271993,
                "recall": 0.9955232232792389,
                "f1-score": 0.9955231868279693,
                "support": 1787.0
            },
            "cross-entropy": 0.04576820802384423,
            "roc-auc": 0.9999586627784627,
            "score": 0.9955232232792389
        },
        "val": {
            "0": {
                "precision": 0.8839285714285714,
                "recall": 0.8181818181818182,
                "f1-score": 0.849785407725322,
                "support": 121.0
            },
            "1": {
                "precision": 0.8135593220338984,
                "recall": 0.8807339449541285,
                "f1-score": 0.8458149779735683,
                "support": 109.0
            },
            "accuracy": 0.8478260869565217,
            "macro avg": {
                "precision": 0.8487439467312349,
                "recall": 0.8494578815679734,
                "f1-score": 0.8478001928494452,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8505796662806612,
                "recall": 0.8478260869565217,
                "f1-score": 0.8479037692777517,
                "support": 230.0
            },
            "cross-entropy": 0.5522138264006652,
            "roc-auc": 0.8889225870043218,
            "score": 0.8478260869565217
        },
        "test": {
            "0": {
                "precision": 0.7821011673151751,
                "recall": 0.7821011673151751,
                "f1-score": 0.7821011673151751,
                "support": 257.0
            },
            "1": {
                "precision": 0.8,
                "recall": 0.8,
                "f1-score": 0.8000000000000002,
                "support": 280.0
            },
            "accuracy": 0.7914338919925512,
            "macro avg": {
                "precision": 0.7910505836575876,
                "recall": 0.7910505836575876,
                "f1-score": 0.7910505836575876,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7914338919925512,
                "recall": 0.7914338919925512,
                "f1-score": 0.7914338919925513,
                "support": 537.0
            },
            "cross-entropy": 0.5137902434608635,
            "roc-auc": 0.8767509727626459,
            "score": 0.7914338919925512
        }
    }
}
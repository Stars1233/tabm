{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.996662958843159,
                "recall": 0.9944506104328524,
                "f1-score": 0.9955555555555555,
                "support": 901.0
            },
            "1": {
                "precision": 0.9943693693693694,
                "recall": 0.9966139954853274,
                "f1-score": 0.9954904171364151,
                "support": 886.0
            },
            "accuracy": 0.9955232232792389,
            "macro avg": {
                "precision": 0.9955161641062642,
                "recall": 0.9955323029590899,
                "f1-score": 0.9955229863459854,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9955257902512298,
                "recall": 0.9955232232792389,
                "f1-score": 0.9955232597305089,
                "support": 1787.0
            },
            "cross-entropy": 0.05795706580898206,
            "roc-auc": 0.9999160701803615,
            "score": 0.9955232232792389
        },
        "val": {
            "0": {
                "precision": 0.7982456140350878,
                "recall": 0.8053097345132744,
                "f1-score": 0.8017621145374448,
                "support": 113.0
            },
            "1": {
                "precision": 0.8103448275862069,
                "recall": 0.8034188034188035,
                "f1-score": 0.8068669527896996,
                "support": 117.0
            },
            "accuracy": 0.8043478260869565,
            "macro avg": {
                "precision": 0.8042952208106473,
                "recall": 0.8043642689660389,
                "f1-score": 0.8043145336635722,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8044004313632658,
                "recall": 0.8043478260869565,
                "f1-score": 0.8043589235614179,
                "support": 230.0
            },
            "cross-entropy": 0.5220075473552807,
            "roc-auc": 0.8691475682626125,
            "score": 0.8043478260869565
        },
        "test": {
            "0": {
                "precision": 0.8095238095238095,
                "recall": 0.7756653992395437,
                "f1-score": 0.7922330097087379,
                "support": 263.0
            },
            "1": {
                "precision": 0.7929824561403509,
                "recall": 0.8248175182481752,
                "f1-score": 0.8085867620751341,
                "support": 274.0
            },
            "accuracy": 0.8007448789571695,
            "macro avg": {
                "precision": 0.8012531328320802,
                "recall": 0.8002414587438594,
                "f1-score": 0.800409885891936,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8010837148737766,
                "recall": 0.8007448789571695,
                "f1-score": 0.8005773824245527,
                "support": 537.0
            },
            "cross-entropy": 0.517128744631312,
            "roc-auc": 0.8710138491854237,
            "score": 0.8007448789571695
        }
    }
}
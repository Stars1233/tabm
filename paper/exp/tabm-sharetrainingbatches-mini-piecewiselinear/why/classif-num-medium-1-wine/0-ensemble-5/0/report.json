{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9895348837209302,
                "recall": 0.9487179487179487,
                "f1-score": 0.9686966420034149,
                "support": 897.0
            },
            "1": {
                "precision": 0.9503775620280475,
                "recall": 0.9898876404494382,
                "f1-score": 0.9697303247110622,
                "support": 890.0
            },
            "accuracy": 0.9692221600447678,
            "macro avg": {
                "precision": 0.9699562228744889,
                "recall": 0.9693027945836934,
                "f1-score": 0.9692134833572386,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9700329160059523,
                "recall": 0.9692221600447678,
                "f1-score": 0.9692114587968151,
                "support": 1787.0
            },
            "cross-entropy": 0.16465673149296206,
            "roc-auc": 0.996947377650846,
            "score": 0.9692221600447678
        },
        "val": {
            "0": {
                "precision": 0.8260869565217391,
                "recall": 0.7851239669421488,
                "f1-score": 0.8050847457627119,
                "support": 121.0
            },
            "1": {
                "precision": 0.7739130434782608,
                "recall": 0.8165137614678899,
                "f1-score": 0.7946428571428571,
                "support": 109.0
            },
            "accuracy": 0.8,
            "macro avg": {
                "precision": 0.8,
                "recall": 0.8008188642050194,
                "f1-score": 0.7998638014527846,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8013610586011342,
                "recall": 0.8,
                "f1-score": 0.8001361985472154,
                "support": 230.0
            },
            "cross-entropy": 0.4607454734582644,
            "roc-auc": 0.8685268026385625,
            "score": 0.8
        },
        "test": {
            "0": {
                "precision": 0.8235294117647058,
                "recall": 0.7027027027027027,
                "f1-score": 0.7583333333333333,
                "support": 259.0
            },
            "1": {
                "precision": 0.7563291139240507,
                "recall": 0.8597122302158273,
                "f1-score": 0.8047138047138047,
                "support": 278.0
            },
            "accuracy": 0.7839851024208566,
            "macro avg": {
                "precision": 0.7899292628443783,
                "recall": 0.781207466459265,
                "f1-score": 0.781523569023569,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7887404307596739,
                "recall": 0.7839851024208566,
                "f1-score": 0.7823440801559982,
                "support": 537.0
            },
            "cross-entropy": 0.47960397040221725,
            "roc-auc": 0.8496291769673064,
            "score": 0.7839851024208566
        }
    }
}
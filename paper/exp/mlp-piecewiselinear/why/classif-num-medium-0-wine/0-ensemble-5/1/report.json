{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9732484076433121,
                "recall": 0.8526785714285714,
                "f1-score": 0.908982748364069,
                "support": 896.0
            },
            "1": {
                "precision": 0.8682634730538922,
                "recall": 0.9764309764309764,
                "f1-score": 0.9191759112519811,
                "support": 891.0
            },
            "accuracy": 0.9143816452154448,
            "macro avg": {
                "precision": 0.9207559403486021,
                "recall": 0.9145547739297739,
                "f1-score": 0.914079329808025,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9209028135083523,
                "recall": 0.9143816452154448,
                "f1-score": 0.9140650696472977,
                "support": 1787.0
            },
            "cross-entropy": 0.22814633544029847,
            "roc-auc": 0.9783336840628507,
            "score": 0.9143816452154448
        },
        "val": {
            "0": {
                "precision": 0.8598130841121495,
                "recall": 0.8440366972477065,
                "f1-score": 0.8518518518518519,
                "support": 109.0
            },
            "1": {
                "precision": 0.8617886178861789,
                "recall": 0.8760330578512396,
                "f1-score": 0.8688524590163934,
                "support": 121.0
            },
            "accuracy": 0.8608695652173913,
            "macro avg": {
                "precision": 0.8608008509991643,
                "recall": 0.860034877549473,
                "f1-score": 0.8603521554341227,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8608523866628345,
                "recall": 0.8608695652173913,
                "f1-score": 0.8607956495340672,
                "support": 230.0
            },
            "cross-entropy": 0.33079775752649315,
            "roc-auc": 0.92668132534688,
            "score": 0.8608695652173913
        },
        "test": {
            "0": {
                "precision": 0.8663594470046083,
                "recall": 0.6911764705882353,
                "f1-score": 0.7689161554192229,
                "support": 272.0
            },
            "1": {
                "precision": 0.7375,
                "recall": 0.8905660377358491,
                "f1-score": 0.8068376068376069,
                "support": 265.0
            },
            "accuracy": 0.7895716945996276,
            "macro avg": {
                "precision": 0.8019297235023042,
                "recall": 0.7908712541620422,
                "f1-score": 0.7878768811284149,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8027695895442336,
                "recall": 0.7895716945996276,
                "f1-score": 0.7876297208305297,
                "support": 537.0
            },
            "cross-entropy": 0.49841019709363976,
            "roc-auc": 0.861015538290788,
            "score": 0.7895716945996276
        }
    }
}
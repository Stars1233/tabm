{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-2-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9858490566037735,
                "recall": 0.9176728869374314,
                "f1-score": 0.9505400795906765,
                "support": 911.0
            },
            "1": {
                "precision": 0.9201277955271565,
                "recall": 0.9863013698630136,
                "f1-score": 0.9520661157024792,
                "support": 876.0
            },
            "accuracy": 0.9513150531617236,
            "macro avg": {
                "precision": 0.9529884260654651,
                "recall": 0.9519871284002226,
                "f1-score": 0.9513030976465779,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9536320310284425,
                "recall": 0.9513150531617236,
                "f1-score": 0.9512881532526459,
                "support": 1787.0
            },
            "cross-entropy": 0.13765099098233988,
            "roc-auc": 0.9924665052704389,
            "score": 0.9513150531617236
        },
        "val": {
            "0": {
                "precision": 0.9166666666666666,
                "recall": 0.7333333333333333,
                "f1-score": 0.8148148148148148,
                "support": 105.0
            },
            "1": {
                "precision": 0.8082191780821918,
                "recall": 0.944,
                "f1-score": 0.8708487084870847,
                "support": 125.0
            },
            "accuracy": 0.8478260869565217,
            "macro avg": {
                "precision": 0.8624429223744292,
                "recall": 0.8386666666666667,
                "f1-score": 0.8428317616509498,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8577278141751042,
                "recall": 0.8478260869565217,
                "f1-score": 0.8452680178975702,
                "support": 230.0
            },
            "cross-entropy": 0.5102880940574674,
            "roc-auc": 0.8627809523809523,
            "score": 0.8478260869565217
        },
        "test": {
            "0": {
                "precision": 0.8376068376068376,
                "recall": 0.7509578544061303,
                "f1-score": 0.7919191919191919,
                "support": 261.0
            },
            "1": {
                "precision": 0.7854785478547854,
                "recall": 0.8623188405797102,
                "f1-score": 0.8221070811744388,
                "support": 276.0
            },
            "accuracy": 0.8081936685288641,
            "macro avg": {
                "precision": 0.8115426927308116,
                "recall": 0.8066383474929202,
                "f1-score": 0.8070131365468154,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8108146439912578,
                "recall": 0.8081936685288641,
                "f1-score": 0.8074347551118327,
                "support": 537.0
            },
            "cross-entropy": 0.5259198515173925,
            "roc-auc": 0.877116997057027,
            "score": 0.8081936685288641
        }
    }
}
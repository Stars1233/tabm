{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9888268156424581,
                "recall": 0.9844271412680756,
                "f1-score": 0.9866220735785953,
                "support": 899.0
            },
            "1": {
                "precision": 0.984304932735426,
                "recall": 0.9887387387387387,
                "f1-score": 0.9865168539325843,
                "support": 888.0
            },
            "accuracy": 0.9865696698377169,
            "macro avg": {
                "precision": 0.986565874188942,
                "recall": 0.9865829400034072,
                "f1-score": 0.9865694637555897,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.986579791567783,
                "recall": 0.9865696698377169,
                "f1-score": 0.9865697875989323,
                "support": 1787.0
            },
            "cross-entropy": 0.11790007577987593,
            "roc-auc": 0.9990504965477157,
            "score": 0.9865696698377169
        },
        "val": {
            "0": {
                "precision": 0.868421052631579,
                "recall": 0.8181818181818182,
                "f1-score": 0.8425531914893618,
                "support": 121.0
            },
            "1": {
                "precision": 0.8103448275862069,
                "recall": 0.8623853211009175,
                "f1-score": 0.8355555555555555,
                "support": 109.0
            },
            "accuracy": 0.8391304347826087,
            "macro avg": {
                "precision": 0.8393829401088929,
                "recall": 0.8402835696413679,
                "f1-score": 0.8390543735224587,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8408979720665983,
                "recall": 0.8391304347826087,
                "f1-score": 0.8392369205468188,
                "support": 230.0
            },
            "cross-entropy": 0.44316580207534173,
            "roc-auc": 0.8889225870043218,
            "score": 0.8391304347826087
        },
        "test": {
            "0": {
                "precision": 0.8048780487804879,
                "recall": 0.7704280155642024,
                "f1-score": 0.7872763419483101,
                "support": 257.0
            },
            "1": {
                "precision": 0.7972508591065293,
                "recall": 0.8285714285714286,
                "f1-score": 0.8126094570928197,
                "support": 280.0
            },
            "accuracy": 0.8007448789571695,
            "macro avg": {
                "precision": 0.8010644539435086,
                "recall": 0.7994997220678155,
                "f1-score": 0.7999428995205649,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8009011156171575,
                "recall": 0.8007448789571695,
                "f1-score": 0.8004854150217975,
                "support": 537.0
            },
            "cross-entropy": 0.4436315665955806,
            "roc-auc": 0.8741801000555864,
            "score": 0.8007448789571695
        }
    }
}
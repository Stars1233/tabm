{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9944196428571429,
                "recall": 0.9889012208657048,
                "f1-score": 0.991652754590985,
                "support": 901.0
            },
            "1": {
                "precision": 0.9887766554433222,
                "recall": 0.9943566591422122,
                "f1-score": 0.9915588069780529,
                "support": 886.0
            },
            "accuracy": 0.9916060436485731,
            "macro avg": {
                "precision": 0.9915981491502326,
                "recall": 0.9916289400039584,
                "f1-score": 0.9916057807845189,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9916218326452542,
                "recall": 0.9916060436485731,
                "f1-score": 0.9916061750806,
                "support": 1787.0
            },
            "cross-entropy": 0.0944183310282641,
            "roc-auc": 0.9997970652122172,
            "score": 0.9916060436485731
        },
        "val": {
            "0": {
                "precision": 0.822429906542056,
                "recall": 0.7787610619469026,
                "f1-score": 0.7999999999999999,
                "support": 113.0
            },
            "1": {
                "precision": 0.7967479674796748,
                "recall": 0.8376068376068376,
                "f1-score": 0.8166666666666667,
                "support": 117.0
            },
            "accuracy": 0.808695652173913,
            "macro avg": {
                "precision": 0.8095889370108654,
                "recall": 0.8081839497768701,
                "f1-score": 0.8083333333333333,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8093656158016274,
                "recall": 0.808695652173913,
                "f1-score": 0.8084782608695652,
                "support": 230.0
            },
            "cross-entropy": 0.4354187833372469,
            "roc-auc": 0.8814764389985629,
            "score": 0.808695652173913
        },
        "test": {
            "0": {
                "precision": 0.8396624472573839,
                "recall": 0.7566539923954373,
                "f1-score": 0.7960000000000002,
                "support": 263.0
            },
            "1": {
                "precision": 0.7866666666666666,
                "recall": 0.8613138686131386,
                "f1-score": 0.8222996515679442,
                "support": 274.0
            },
            "accuracy": 0.8100558659217877,
            "macro avg": {
                "precision": 0.8131645569620253,
                "recall": 0.808983930504288,
                "f1-score": 0.8091498257839722,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8126217696375393,
                "recall": 0.8100558659217877,
                "f1-score": 0.8094191890681876,
                "support": 537.0
            },
            "cross-entropy": 0.43764265095085436,
            "roc-auc": 0.8816990924481696,
            "score": 0.8100558659217877
        }
    }
}
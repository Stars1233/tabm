{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9966254218222722,
                "recall": 0.9888392857142857,
                "f1-score": 0.9927170868347339,
                "support": 896.0
            },
            "1": {
                "precision": 0.9888641425389755,
                "recall": 0.9966329966329966,
                "f1-score": 0.9927333705980994,
                "support": 891.0
            },
            "accuracy": 0.9927252378287633,
            "macro avg": {
                "precision": 0.9927447821806239,
                "recall": 0.9927361411736412,
                "f1-score": 0.9927252287164167,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9927556401538797,
                "recall": 0.9927252378287633,
                "f1-score": 0.9927252059355502,
                "support": 1787.0
            },
            "cross-entropy": 0.08900343241597061,
            "roc-auc": 0.9997306898348566,
            "score": 0.9927252378287633
        },
        "val": {
            "0": {
                "precision": 0.8421052631578947,
                "recall": 0.8807339449541285,
                "f1-score": 0.8609865470852017,
                "support": 109.0
            },
            "1": {
                "precision": 0.8879310344827587,
                "recall": 0.8512396694214877,
                "f1-score": 0.869198312236287,
                "support": 121.0
            },
            "accuracy": 0.8652173913043478,
            "macro avg": {
                "precision": 0.8650181488203267,
                "recall": 0.8659868071878081,
                "f1-score": 0.8650924296607443,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8662136037244534,
                "recall": 0.8652173913043478,
                "f1-score": 0.8653066496212074,
                "support": 230.0
            },
            "cross-entropy": 0.37641347479626636,
            "roc-auc": 0.9263780423079839,
            "score": 0.8652173913043478
        },
        "test": {
            "0": {
                "precision": 0.8366533864541833,
                "recall": 0.7720588235294118,
                "f1-score": 0.8030592734225621,
                "support": 272.0
            },
            "1": {
                "precision": 0.7832167832167832,
                "recall": 0.8452830188679246,
                "f1-score": 0.8130671506352087,
                "support": 265.0
            },
            "accuracy": 0.8081936685288641,
            "macro avg": {
                "precision": 0.8099350848354833,
                "recall": 0.8086709211986682,
                "f1-score": 0.8080632120288854,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8102833680968071,
                "recall": 0.8081936685288641,
                "f1-score": 0.8079979837788961,
                "support": 537.0
            },
            "cross-entropy": 0.5028231656858086,
            "roc-auc": 0.8759295227524971,
            "score": 0.8081936685288641
        }
    }
}
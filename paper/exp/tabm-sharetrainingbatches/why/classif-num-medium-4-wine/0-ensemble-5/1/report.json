{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 0.9977753058954394,
                "f1-score": 0.9988864142538975,
                "support": 899.0
            },
            "1": {
                "precision": 0.9977528089887641,
                "recall": 1.0,
                "f1-score": 0.998875140607424,
                "support": 888.0
            },
            "accuracy": 0.9988808058198098,
            "macro avg": {
                "precision": 0.9988764044943821,
                "recall": 0.9988876529477198,
                "f1-score": 0.9988807774306607,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9988833208629113,
                "recall": 0.9988808058198098,
                "f1-score": 0.9988808121285093,
                "support": 1787.0
            },
            "cross-entropy": 0.0805117838615218,
            "roc-auc": 0.9999987473569232,
            "score": 0.9988808058198098
        },
        "val": {
            "0": {
                "precision": 0.8738738738738738,
                "recall": 0.8016528925619835,
                "f1-score": 0.8362068965517241,
                "support": 121.0
            },
            "1": {
                "precision": 0.7983193277310925,
                "recall": 0.8715596330275229,
                "f1-score": 0.8333333333333334,
                "support": 109.0
            },
            "accuracy": 0.8347826086956521,
            "macro avg": {
                "precision": 0.8360966008024832,
                "recall": 0.8366062627947533,
                "f1-score": 0.8347701149425287,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8380675889627296,
                "recall": 0.8347826086956521,
                "f1-score": 0.8348450774612695,
                "support": 230.0
            },
            "cross-entropy": 0.44652057739363327,
            "roc-auc": 0.8925619834710743,
            "score": 0.8347826086956521
        },
        "test": {
            "0": {
                "precision": 0.8163265306122449,
                "recall": 0.7782101167315175,
                "f1-score": 0.7968127490039841,
                "support": 257.0
            },
            "1": {
                "precision": 0.8047945205479452,
                "recall": 0.8392857142857143,
                "f1-score": 0.8216783216783218,
                "support": 280.0
            },
            "accuracy": 0.8100558659217877,
            "macro avg": {
                "precision": 0.8105605255800951,
                "recall": 0.8087479155086159,
                "f1-score": 0.809245535341153,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8103135644707106,
                "recall": 0.8100558659217877,
                "f1-score": 0.8097780382941416,
                "support": 537.0
            },
            "cross-entropy": 0.4246612269636842,
            "roc-auc": 0.8824624791550861,
            "score": 0.8100558659217877
        }
    }
}
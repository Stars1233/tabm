{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.98698224852071,
                "recall": 0.9308035714285714,
                "f1-score": 0.95807007466973,
                "support": 896.0
            },
            "1": {
                "precision": 0.9341825902335457,
                "recall": 0.9876543209876543,
                "f1-score": 0.9601745771958539,
                "support": 891.0
            },
            "accuracy": 0.9591494124230554,
            "macro avg": {
                "precision": 0.9605824193771278,
                "recall": 0.9592289462081128,
                "f1-score": 0.9591223259327919,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9606562857149665,
                "recall": 0.9591494124230554,
                "f1-score": 0.9591193817490676,
                "support": 1787.0
            },
            "cross-entropy": 0.1889771037952801,
            "roc-auc": 0.9959753787878788,
            "score": 0.9591494124230554
        },
        "val": {
            "0": {
                "precision": 0.8454545454545455,
                "recall": 0.8532110091743119,
                "f1-score": 0.8493150684931506,
                "support": 109.0
            },
            "1": {
                "precision": 0.8666666666666667,
                "recall": 0.859504132231405,
                "f1-score": 0.8630705394190872,
                "support": 121.0
            },
            "accuracy": 0.8565217391304348,
            "macro avg": {
                "precision": 0.8560606060606061,
                "recall": 0.8563575707028585,
                "f1-score": 0.8561928039561189,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8566139657444005,
                "recall": 0.8565217391304348,
                "f1-score": 0.8565516423280999,
                "support": 230.0
            },
            "cross-entropy": 0.3653021396566613,
            "roc-auc": 0.9196299946925468,
            "score": 0.8565217391304348
        },
        "test": {
            "0": {
                "precision": 0.8706896551724138,
                "recall": 0.7426470588235294,
                "f1-score": 0.8015873015873016,
                "support": 272.0
            },
            "1": {
                "precision": 0.7704918032786885,
                "recall": 0.8867924528301887,
                "f1-score": 0.8245614035087719,
                "support": 265.0
            },
            "accuracy": 0.813780260707635,
            "macro avg": {
                "precision": 0.8205907292255512,
                "recall": 0.8147197558268591,
                "f1-score": 0.8130743525480368,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8212437878505569,
                "recall": 0.813780260707635,
                "f1-score": 0.8129246144535766,
                "support": 537.0
            },
            "cross-entropy": 0.4386608730490188,
            "roc-auc": 0.8772613762486127,
            "score": 0.813780260707635
        }
    }
}